{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'Greys_r'\n",
    "rc('figure', figsize = (8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomography Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 32\n",
    "n_angles = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_circle(size, supersampling=4):\n",
    "    ''' Create a test image for reconstruction '''\n",
    "    image = Image.new('F', (size * supersampling, size * supersampling), \n",
    "                      (0))\n",
    "    draw = ImageDraw.ImageDraw(image)\n",
    "\n",
    "    # add circle\n",
    "    center = (size) * supersampling / 2\n",
    "    radius = size * supersampling * 0.35\n",
    "    draw.ellipse((center - radius, center - radius, center + radius - 0.3, center + radius - 0.5), fill=(0.3))\n",
    "\n",
    "    # add offset box 1\n",
    "    offset = size * supersampling / 2 * 0.07\n",
    "    width = size * supersampling / 2 * 0.30\n",
    "    draw.rectangle((center + offset, center + offset, center + offset + width, center + offset + width), fill=(1.0))\n",
    "    \n",
    "    # add offset box 2\n",
    "    offset = size * supersampling / 2 * 0.07\n",
    "    width = size * supersampling / 2 * 0.20\n",
    "    draw.rectangle((center - offset, center - offset, center - offset + width, center - offset + width), fill=(0.15))\n",
    "\n",
    "    image = image.resize((size, size), Image.ANTIALIAS)\n",
    "\n",
    "    return np.array(image, dtype=np.float64)\n",
    "\n",
    "\n",
    "def plot_image(image, title='Image'):\n",
    "    plt.figure()\n",
    "    plt.imshow(image, interpolation='none')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_circle = create_circle(size, supersampling=1)\n",
    "plot_image(m_circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinogram\n",
    "\n",
    "![Backprojection](backprojection.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sinogram(image, n_angles):\n",
    "    ''' For a numpy array image create a sinogram at the input angles '''\n",
    "    angles = np.linspace(0., 180., n_angles, endpoint=False)\n",
    "\n",
    "    sinogram = np.zeros((image.shape[0], n_angles),\n",
    "                        dtype=np.float64)\n",
    "\n",
    "    for i, angle in enumerate(angles):\n",
    "        rot_image = rotate(image, angle, reshape=False, order=1, mode='constant', cval=0.0)\n",
    "        projection = np.sum(rot_image, axis=1)\n",
    "        sinogram[:, i] = projection\n",
    "\n",
    "    return sinogram\n",
    "\n",
    "\n",
    "def plot_sinogram(sinogram, title='Sinogram'):\n",
    "    plt.figure()\n",
    "    plt.imshow(sinogram, interpolation='none')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_circle = create_sinogram(m_circle, n_angles)\n",
    "plot_sinogram(d_circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Recover the Model (Image)?\n",
    "\n",
    "![fbp](fbp.gif)\n",
    "\n",
    " - Filtered Back Projection (FBP) was/is the most popular method. Casting shadows from each sinogram back on to an image.\n",
    "     - Pro: Fast, computationally simple\n",
    "     - Con: Does not compensate for statistical noise, systematic detector noise. Requires more data (dose) for good images\n",
    " - Inverse Methods\n",
    "     - Pro: Can include noise compensation and detector effects, less data (dose) required\n",
    "     - Con: More computationally intensive (not as relevant with GPUs), more math (pro?)\n",
    "     \n",
    "     \n",
    "Going to skip FBP, extensive literature on the topic exists. Reccomend chapter 3 of Kak & Slaney's book on the topic\n",
    "\n",
    "http://www.slaney.org/pct/pct-toc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Detector Response, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by building a mathematical model of the process occurring, taking an image/model ($m$) and translating into a sinogram ($d$). This is done through a response function ($G$)\n",
    "\n",
    "$$\n",
    "G(m) = d\n",
    "$$\n",
    "\n",
    "Tomography is a linear process. That is, $G(m_1 + m_2) = G(m_1) + G(m_2) = d_1 + d_2$, so $G$ can be represented as a plain matrix\n",
    "\n",
    "$$\n",
    "G~m = d\n",
    "$$\n",
    "\n",
    "To calculate $G$ in our example, we will:\n",
    "- Create images of single pixels\n",
    "- Compute the sinogram\n",
    "- and store that as columns in $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create images of single pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_single_pixel_image(size, index):\n",
    "    ''' Create image for a single intensity pixel '''\n",
    "    image = np.zeros((size, size), dtype=np.float64)\n",
    "\n",
    "    if type(index) is int:\n",
    "        i1 = int(index / size)\n",
    "        i2 = index % size\n",
    "        image[i1, i2] = 1\n",
    "    else:\n",
    "        image[index[0], index[1]] = 1\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixel_image = create_single_pixel_image(size, 616)\n",
    "plot_image(pixel_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the sinogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_pixel = create_sinogram(pixel_image, n_angles)\n",
    "plot_sinogram(d_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store as columns in G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def circle_mask(size):\n",
    "    ''' Create a mask of array elements which form a centered circle in the image. '''\n",
    "\n",
    "    xx, yy = np.mgrid[:size, :size]\n",
    "    circle = (xx - (size-1) / 2.)**2 + (yy - (size-1) / 2.) ** 2 < ((size-1) / 2.) ** 2\n",
    "    return circle\n",
    "\n",
    "def calculate_transfer_matrix(size, n_angles):\n",
    "    ''' For pixels in circle mask, store the response of each pixel '''\n",
    "    \n",
    "    mask = circle_mask(size)\n",
    "    index_array = np.transpose(np.where(mask == True))\n",
    "\n",
    "    n_image = np.size(index_array, 0)\n",
    "    n_measure = size * n_angles\n",
    "\n",
    "    transfer_matrix = np.zeros((n_measure, n_image), dtype=np.float64)\n",
    "\n",
    "    for i, index in enumerate(index_array):\n",
    "        impulse = create_single_pixel_image(size, index)\n",
    "        response = create_sinogram(impulse, n_angles).flatten()\n",
    "        transfer_matrix[:, i] = response\n",
    "\n",
    "    return transfer_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_response = calculate_transfer_matrix(size, n_angles)\n",
    "plot_sinogram(G_response[:, 616].reshape((size, n_angles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using Forward Projection\n",
    "\n",
    "As a quick test compare by calculating $G~m$, the _forward projection_, which should equal our previous $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_project(size, n_angles, G, m):\n",
    "    mask = circle_mask(size)\n",
    "    d = m[mask] @ G.T\n",
    "    return d.reshape(size, n_angles)\n",
    "\n",
    "forward_image = forward_project(size, n_angles, G_response, m_circle)\n",
    "plot_image(forward_image, title='Forward Image')\n",
    "plot_image(d_circle, title='Sinogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Methods\n",
    "\n",
    "Now our example is fully setup. We have a response $G$ which will transform an image $m$ into a sinogram $d$. Now our goal is, given $d$ and $G$ how do we recover the image $m$? \n",
    "\n",
    "Said mathematically,\n",
    "$$\n",
    "G~m = d\n",
    "$$\n",
    "Find $m$ given $d$ and $G$.\n",
    "\n",
    "The simplest possible approach,\n",
    "$$\n",
    "m = G^{-1}~d\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_inverse = np.linalg.inv(G_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, $G$ isn't square.\n",
    "\n",
    "This can be fixed though by multiplying both sides of $G~m = d$ by $G^{T}$.\n",
    "\n",
    "$$\n",
    "G~m=d \\\\\n",
    "G^{T} G ~ m = G^T ~ d \\\\\n",
    "m = (G G^{T})^{-1} G^T ~ d\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_direct(d, G, size):\n",
    "    lhs = G.T @ G\n",
    "    rhs = G.T @ d.flatten()\n",
    "    inv = np.linalg.inv(lhs)\n",
    "    m_elements = inv @ rhs\n",
    "    \n",
    "    # take care of mask element matching\n",
    "    mask = circle_mask(size)\n",
    "    m = np.zeros((size * size), dtype=np.float64)\n",
    "    m[mask.flatten()] = m_elements.flatten()\n",
    "    m = m.reshape((size, size))\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_direct = solve_direct(d_circle, G_response, size)\n",
    "plot_image(m_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect recovery, our job is done!\n",
    "\n",
    "But wait, this is using _perfect_ data without any noise at all. In real measurements we don't have the luxury of giving an infinite amount of dose to a patient (at least not ethically). Let's see what happens if we add just the smallest amount of statistical noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_circle_noise = d_circle[:]\n",
    "d_circle_noise *= 1 + 0.01 * (2 * np.random.random(d_circle_noise.shape) - 1)\n",
    "d_circle_noise[d_circle_noise < 0] = 0\n",
    "\n",
    "plot_sinogram(d_circle, title='Without Noise')\n",
    "plot_sinogram(d_circle_noise, title='With Noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_direct_noise = solve_direct(d_circle_noise, G_response, size)\n",
    "plot_image(m_direct_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? The difference in the sinograms are miniscule, on the order of numerical floating point errors. This can't possibly be right, let's look at the forward projection of the image and see if it matches the original sinogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forward_noise_image = forward_project(size, n_angles, G_response, m_direct_noise)\n",
    "plot_image(forward_noise_image, title='Forward Noise Image')\n",
    "plot_image(d_circle, title='Sinogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while the images are very different, the data (sinograms) are practically identical. This is due to a concept called _ill-posed_ or _ill-conditioned_, small changes in the data lead to very large changes in the recovered model. This property can be measured in several ways. One is by examining the spectrum of singular values of a matrix in a Singular Value Decomposition of $G$, another is by calculating a quantity called the _condition number_ of $G$. For brevity I'm skipping both of those to move on to how to solve it. One method to avoid ill-posedness is using SVD is to exclude small singular values, however regularization is a more general and powerful approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Methods\n",
    "\n",
    "To backtrack, the goal has been to find models $m$ which match our observed data $d$ as best as possible. That is to minimize the error between our calculation (forward projection data) and the measured data.\n",
    "\n",
    "This is represented as minimizing the sums of square residuals\n",
    "$$\n",
    "\\min \\lVert G~m - d \\rVert_2^2\n",
    "$$\n",
    "\n",
    "In regularization we select a solution by limiting the complexity of the model (select against wild spikes in the data, random results). This can be accomplished in several ways.\n",
    "\n",
    "By minimizing the norm of $m$ and limiting acceptable error\n",
    "$$\n",
    "\\min \\lVert m \\rVert_2^2 \\\\\n",
    "\\lVert G~m - d \\rVert_2^2 \\leq \\delta\n",
    "$$\n",
    "\n",
    "By minimizing the acceptable error and limiting the norm of $m$\n",
    "$$\n",
    "\\min \\lVert G~m - d \\rVert_2^2 \\\\\n",
    "\\lVert m \\rVert_2^2 \\leq \\epsilon\n",
    "$$\n",
    "\n",
    "Or minimizing the combined error and norm,\n",
    "$$\n",
    "\\min~ \\lVert G~m - d \\rVert_2^2 + \\alpha \\lVert m \\rVert_2^2\n",
    "$$\n",
    "This is _zeroth order Tikhonov Regularization_ aka _Ridge Regression_.\n",
    "\n",
    "This can be solved by changing the least squares problem\n",
    "$$\n",
    "\\min \\left\\lVert \n",
    "G~m - d\n",
    "\\right\\rVert_2^2\n",
    "$$\n",
    "\n",
    "into\n",
    "\n",
    "$$\n",
    "\\min \\left\\lVert \n",
    "\\begin{bmatrix}\n",
    "G \\\\ \n",
    "\\alpha I\n",
    "\\end{bmatrix}\n",
    "m\n",
    "- \n",
    "\\begin{bmatrix}\n",
    "d \\\\ \n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\right\\rVert_2^2\n",
    "$$\n",
    "\n",
    "which can be solved using the normal equations (again, skipping) and simplifying to as\n",
    "\n",
    "$$\n",
    "(G^T G + \\alpha^2 I)~m = G^T d\n",
    "$$\n",
    "\n",
    "So just invert the left side (or more practically solve using SVD) and we're good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_tikhonov(d, G, size, alpha=0, use_mask=True):\n",
    "    gamma = alpha * np.identity(np.size(G, 1))\n",
    "\n",
    "    lhs = G.T @ G + gamma.T @ gamma\n",
    "    rhs = G.T @ d.flatten()\n",
    "    inv = np.linalg.inv(lhs)\n",
    "    m_elements = inv @ rhs\n",
    "    \n",
    "    if use_mask:\n",
    "        # take care of mask element matching\n",
    "        mask = circle_mask(size)\n",
    "        m = np.zeros((size * size), dtype=np.float64)\n",
    "        m[mask.flatten()] = m_elements.flatten()\n",
    "        m = m.reshape((size, size))\n",
    "\n",
    "        return m\n",
    "    else:\n",
    "        return m_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_noise_tikhonov = solve_tikhonov(d_circle_noise, G_response, size, alpha=10)\n",
    "plot_image(m_noise_tikhonov, title='Tikhonov, Alpha = 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except we don't know $\\alpha$! There are several ways for determing $\\alpha$, one of the most straight forward way is to explore a range of values for $\\alpha$ and for each result plot the solution norm $\\lVert m \\rVert_2^2$ vs the residual norm $\\lVert Gm - d \\rVert_2^2$. This will trace out a graph called the L-Curve and you select the $\\alpha$ at the elbow of the graph which represents a trade-off between the norms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trace_lcurve(d, G, size, alphas):\n",
    "    norms = np.zeros(len(alphas))\n",
    "    residuals = np.zeros(len(alphas))\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        m_alpha = solve_tikhonov(d, G, size, alpha=alpha, use_mask=False)\n",
    "        residuals[i] = np.linalg.norm(G @ m_alpha.flatten() - d.flatten())\n",
    "        norms[i] = np.linalg.norm(m_alpha)\n",
    "    return norms, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = alphas = np.logspace(-3, 1, 100)\n",
    "n, r = trace_lcurve(d_circle_noise, G_response, size, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.loglog(n, r)\n",
    "alphai = 50\n",
    "plt.scatter(n[alphai], r[alphai])\n",
    "plt.title('Alpha = ' + str(alphas[alphai]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_noise_tikhonov = solve_tikhonov(d_circle_noise, G_response, size, alpha=alphas[alphai])\n",
    "plot_image(m_noise_tikhonov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher Order Tikhonov Regularization\n",
    "\n",
    "Zeroth Order Tikhonov Regularization can be extended to higher order. This is done when we wish to minimize some other feature of the model $\\lVert L~m \\rVert_2^2$ where $L$ could be a first or second derivative selecting flat solutions, or some other measure.\n",
    "\n",
    "$$\n",
    "\\min~ \\lVert G~m - d \\rVert_2^2 + \\alpha \\lVert L ~ m \\rVert_2^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\min \\left\\lVert \n",
    "\\begin{bmatrix}\n",
    "G \\\\ \n",
    "\\alpha L\n",
    "\\end{bmatrix}\n",
    "m\n",
    "- \n",
    "\\begin{bmatrix}\n",
    "d \\\\ \n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\right\\rVert_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_laplacian(size):\n",
    "    mask = circle_mask(size)\n",
    "    index_array = np.transpose(np.where(mask == True))\n",
    "    \n",
    "    L = np.zeros((size, size, len(index_array)))\n",
    "    \n",
    "    for i in range(len(index_array)):\n",
    "        xi = index_array[i, 0]\n",
    "        yi = index_array[i, 1]\n",
    "        L[xi, yi, i] = -4\n",
    "        L[xi+1, yi, i] = 1\n",
    "        L[xi-1, yi, i] = 1\n",
    "        L[xi, yi+1, i] = 1\n",
    "        L[xi, yi-1, i] = 1\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = create_laplacian(size)\n",
    "plot_image(L[:, :, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limage = np.zeros((size, size))\n",
    "limage[mask] = L2.T @ m_circle.flatten()\n",
    "plot_image(limage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_higher_tikhonov(d, G, L, size, alpha=0, use_mask=True):\n",
    "    L2 = L.reshape(L.shape[0] * L.shape[1], -1)\n",
    "    L2 = alpha * L2\n",
    "\n",
    "    lhs = G.T @ G + L2.T @ L2\n",
    "    rhs = G.T @ d.flatten()\n",
    "    inv = np.linalg.inv(lhs)\n",
    "    m_elements = inv @ rhs\n",
    "    \n",
    "    if use_mask:\n",
    "        # take care of mask element matching\n",
    "        mask = circle_mask(size)\n",
    "        m = np.zeros((size * size), dtype=np.float64)\n",
    "        m[mask.flatten()] = m_elements.flatten()\n",
    "        m = m.reshape((size, size))\n",
    "\n",
    "        return m\n",
    "    else:\n",
    "        return m_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_high_t = solve_higher_tikhonov(d_circle_noise, G_response, L, size, alpha=1.1)\n",
    "plot_image(m_high_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm purposefully ignoring the L-curve portion for this one, but for these more advanced problems it's more feasible to use an approximation known as the Generalized Cross Validation metric for selection $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1-Minimizing Algorithms & Compressive Sensing\n",
    "\n",
    "Finally beginning to tie this into compressive sensing, in which we are interested in algorithms for which we assume that some of the model parameters will be zero. Instead of using Tikhonov Regularization to minimize $\\lVert m \\rVert_2^2$ or $\\lVert Lm \\rVert_2^2$, we minimize the number of non-zero entries of $m$ represented as $\\lVert m \\rVert_0$.\n",
    "\n",
    "Compressive sensing has shown that under many robust conditions $\\min \\lVert m \\rVert_0 = \\min \\lVert m \\rVert_1$ and because many algorithms exist for the latter this can be solved for. Our setup is\n",
    "\n",
    "$$\n",
    "\\min~ \\lVert G~m - d \\rVert_2^2 + \\alpha \\lVert L m \\rVert_1\n",
    "$$\n",
    "\n",
    "Which can be solved using a method known as Iterative Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_higher_tikhonov_L1(d, G, L, size, iterations=10, epsilon=0.1, alpha=0, use_mask=True):\n",
    "    mask = circle_mask(size)\n",
    "    index_array = np.transpose(np.where(mask == True))\n",
    "    \n",
    "    L2 = L.reshape(L.shape[0] * L.shape[1], -1)\n",
    "    m_i = np.ones(np.size(index_array, 0))\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        y = L2 @ m_i\n",
    "        y = np.abs(y)\n",
    "        y[y < epsilon] = epsilon\n",
    "        W = np.diag(1 / y)\n",
    "        \n",
    "        lhs = 2 * G.T @ G + alpha * L2.T @ W @ L2\n",
    "        rhs = 2 * G.T @ d.flatten()\n",
    "        \n",
    "        inv = np.linalg.inv(lhs)\n",
    "        m_i = inv @ rhs\n",
    "        \n",
    "    m_elements = m_i\n",
    "    \n",
    "    if use_mask:\n",
    "        # take care of mask element matching\n",
    "        mask = circle_mask(size)\n",
    "        m = np.zeros((size * size), dtype=np.float64)\n",
    "        m[mask.flatten()] = m_elements.flatten()\n",
    "        m = m.reshape((size, size))\n",
    "\n",
    "        return m\n",
    "    else:\n",
    "        return m_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = solve_higher_tikhonov_L1(d_circle_noise, G_response, L, size, iterations=15, epsilon=0.001, alpha=0.1)\n",
    "plot_image(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Inverse Problems\n",
    "\n",
    "All of the previous has been for _linear_ systems. What if we have a system which is non-linear, such as scattering effects?\n",
    "$$\n",
    "G(m) = d\n",
    "$$\n",
    "\n",
    "In general the approach is to treat to problem as linear locally, approximating the system using the jacobian of our $G$ response matrix.\n",
    "\n",
    "$$\n",
    "G(m) \\approx G(m_0) + J(m_0) (m - m_0) \n",
    "$$\n",
    "\n",
    "An analog of Tikhonov Regularization can then be solved interatively using Occam's Inversion method by iteratively solving\n",
    "$$\n",
    "m^{k+1} = \\left( J(m^k)^T J(m^k) + \\alpha^2 L^T L \\right)^{-1} J(m^k) ~ d(m^k)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
